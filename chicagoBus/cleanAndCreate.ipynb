{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Read the Data\n",
      "---\n",
      "Exported data as CSV from [chicago data](https://data.cityofchicago.org/Transportation/CTA-Ridership-Avg-Weekday-Bus-Stop-Boardings-in-Oc/mq3i-nnqe)\n",
      "\n",
      "Let's just read it straight into **`pandas`**, see what we get out."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import print_function, division\n",
      "import pandas as pd\n",
      "print(pd.__version__)\n",
      "pd.options.display.max_rows = 15\n",
      "\n",
      "df = pd.read_csv(\"CTA_Ridership.csv\")\n",
      "df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.18.1\n"
       ]
      },
      {
       "html": [
        "<div style=\"max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>stop_id</th>\n",
        "      <th>on_street</th>\n",
        "      <th>cross_street</th>\n",
        "      <th>routes</th>\n",
        "      <th>boardings</th>\n",
        "      <th>alightings</th>\n",
        "      <th>month_beginning</th>\n",
        "      <th>daytype</th>\n",
        "      <th>location</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>1</td>\n",
        "      <td>JACKSON</td>\n",
        "      <td>AUSTIN</td>\n",
        "      <td>126</td>\n",
        "      <td>183.4</td>\n",
        "      <td>150.0</td>\n",
        "      <td>10/01/2012</td>\n",
        "      <td>Weekday</td>\n",
        "      <td>(41.87632184, -87.77410482)</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>2</td>\n",
        "      <td>JACKSON</td>\n",
        "      <td>MAYFIELD (EXTENDED)</td>\n",
        "      <td>126</td>\n",
        "      <td>5.3</td>\n",
        "      <td>0.2</td>\n",
        "      <td>10/01/2012</td>\n",
        "      <td>Weekday</td>\n",
        "      <td>(41.87706679, -87.77131794)</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>3</td>\n",
        "      <td>JACKSON</td>\n",
        "      <td>MENARD</td>\n",
        "      <td>126</td>\n",
        "      <td>8.3</td>\n",
        "      <td>0.7</td>\n",
        "      <td>10/01/2012</td>\n",
        "      <td>Weekday</td>\n",
        "      <td>(41.87695725, -87.76975039)</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>4</td>\n",
        "      <td>JACKSON</td>\n",
        "      <td>5700 WEST</td>\n",
        "      <td>126</td>\n",
        "      <td>17.9</td>\n",
        "      <td>3.0</td>\n",
        "      <td>10/01/2012</td>\n",
        "      <td>Weekday</td>\n",
        "      <td>(41.87702418, -87.76745055)</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>6</td>\n",
        "      <td>JACKSON</td>\n",
        "      <td>LOTUS</td>\n",
        "      <td>126</td>\n",
        "      <td>74.0</td>\n",
        "      <td>11.2</td>\n",
        "      <td>10/01/2012</td>\n",
        "      <td>Weekday</td>\n",
        "      <td>(41.87651300, -87.76144600)</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5</th>\n",
        "      <td>7</td>\n",
        "      <td>JACKSON</td>\n",
        "      <td>5351 WEST</td>\n",
        "      <td>126</td>\n",
        "      <td>14.3</td>\n",
        "      <td>2.5</td>\n",
        "      <td>10/01/2012</td>\n",
        "      <td>Weekday</td>\n",
        "      <td>(41.87655197, -87.75892544)</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6</th>\n",
        "      <td>8</td>\n",
        "      <td>JACKSON</td>\n",
        "      <td>LOCKWOOD</td>\n",
        "      <td>126</td>\n",
        "      <td>62.4</td>\n",
        "      <td>14.1</td>\n",
        "      <td>10/01/2012</td>\n",
        "      <td>Weekday</td>\n",
        "      <td>(41.87656400, -87.75731300)</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>...</th>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11586</th>\n",
        "      <td>17704</td>\n",
        "      <td>MARQUETTE</td>\n",
        "      <td>CORNELL</td>\n",
        "      <td>6,15,67</td>\n",
        "      <td>69.3</td>\n",
        "      <td>321.3</td>\n",
        "      <td>10/01/2012</td>\n",
        "      <td>Weekday</td>\n",
        "      <td>(41.77514645, -87.58515301)</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11587</th>\n",
        "      <td>17705</td>\n",
        "      <td>STONY ISLAND</td>\n",
        "      <td>MARQUETTE RD</td>\n",
        "      <td>6,15,28,X28</td>\n",
        "      <td>81.2</td>\n",
        "      <td>62.7</td>\n",
        "      <td>10/01/2012</td>\n",
        "      <td>Weekday</td>\n",
        "      <td>(41.77538531, -87.58611272)</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11588</th>\n",
        "      <td>17706</td>\n",
        "      <td>100TH STREET</td>\n",
        "      <td>PAXTON</td>\n",
        "      <td>J14,15</td>\n",
        "      <td>3.6</td>\n",
        "      <td>49.5</td>\n",
        "      <td>10/01/2012</td>\n",
        "      <td>Weekday</td>\n",
        "      <td>(41.71339537, -87.56963306)</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11589</th>\n",
        "      <td>17707</td>\n",
        "      <td>43RD STREET</td>\n",
        "      <td>OAKENWALD</td>\n",
        "      <td>43</td>\n",
        "      <td>21.0</td>\n",
        "      <td>69.1</td>\n",
        "      <td>10/01/2012</td>\n",
        "      <td>Weekday</td>\n",
        "      <td>(41.81685612, -87.59757281)</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11590</th>\n",
        "      <td>17708</td>\n",
        "      <td>43RD STREET</td>\n",
        "      <td>LAKE PARK</td>\n",
        "      <td>43</td>\n",
        "      <td>24.8</td>\n",
        "      <td>0.9</td>\n",
        "      <td>10/01/2012</td>\n",
        "      <td>Weekday</td>\n",
        "      <td>(41.81697313, -87.59910809)</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11591</th>\n",
        "      <td>17709</td>\n",
        "      <td>43RD STREET</td>\n",
        "      <td>BERKELEY</td>\n",
        "      <td>43</td>\n",
        "      <td>14.7</td>\n",
        "      <td>0.9</td>\n",
        "      <td>10/01/2012</td>\n",
        "      <td>Weekday</td>\n",
        "      <td>(41.81695808, -87.60049861)</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11592</th>\n",
        "      <td>17710</td>\n",
        "      <td>S. SHORE DRIVE</td>\n",
        "      <td>76TH STREET</td>\n",
        "      <td>N5,6,26,71</td>\n",
        "      <td>44.6</td>\n",
        "      <td>250.1</td>\n",
        "      <td>10/01/2012</td>\n",
        "      <td>Weekday</td>\n",
        "      <td>(41.75894604, -87.55560586)</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>11593 rows \u00d7 9 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "       stop_id       on_street         cross_street       routes  boardings  \\\n",
        "0            1         JACKSON               AUSTIN          126      183.4   \n",
        "1            2         JACKSON  MAYFIELD (EXTENDED)          126        5.3   \n",
        "2            3         JACKSON               MENARD          126        8.3   \n",
        "3            4         JACKSON            5700 WEST          126       17.9   \n",
        "4            6         JACKSON                LOTUS          126       74.0   \n",
        "5            7         JACKSON            5351 WEST          126       14.3   \n",
        "6            8         JACKSON             LOCKWOOD          126       62.4   \n",
        "...        ...             ...                  ...          ...        ...   \n",
        "11586    17704       MARQUETTE              CORNELL      6,15,67       69.3   \n",
        "11587    17705    STONY ISLAND         MARQUETTE RD  6,15,28,X28       81.2   \n",
        "11588    17706    100TH STREET               PAXTON       J14,15        3.6   \n",
        "11589    17707     43RD STREET            OAKENWALD           43       21.0   \n",
        "11590    17708     43RD STREET            LAKE PARK           43       24.8   \n",
        "11591    17709     43RD STREET             BERKELEY           43       14.7   \n",
        "11592    17710  S. SHORE DRIVE          76TH STREET   N5,6,26,71       44.6   \n",
        "\n",
        "       alightings month_beginning  daytype                     location  \n",
        "0           150.0      10/01/2012  Weekday  (41.87632184, -87.77410482)  \n",
        "1             0.2      10/01/2012  Weekday  (41.87706679, -87.77131794)  \n",
        "2             0.7      10/01/2012  Weekday  (41.87695725, -87.76975039)  \n",
        "3             3.0      10/01/2012  Weekday  (41.87702418, -87.76745055)  \n",
        "4            11.2      10/01/2012  Weekday  (41.87651300, -87.76144600)  \n",
        "5             2.5      10/01/2012  Weekday  (41.87655197, -87.75892544)  \n",
        "6            14.1      10/01/2012  Weekday  (41.87656400, -87.75731300)  \n",
        "...           ...             ...      ...                          ...  \n",
        "11586       321.3      10/01/2012  Weekday  (41.77514645, -87.58515301)  \n",
        "11587        62.7      10/01/2012  Weekday  (41.77538531, -87.58611272)  \n",
        "11588        49.5      10/01/2012  Weekday  (41.71339537, -87.56963306)  \n",
        "11589        69.1      10/01/2012  Weekday  (41.81685612, -87.59757281)  \n",
        "11590         0.9      10/01/2012  Weekday  (41.81697313, -87.59910809)  \n",
        "11591         0.9      10/01/2012  Weekday  (41.81695808, -87.60049861)  \n",
        "11592       250.1      10/01/2012  Weekday  (41.75894604, -87.55560586)  \n",
        "\n",
        "[11593 rows x 9 columns]"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "At first glance, this suggests a few things:\n",
      "\n",
      "  - **`stop_id`** sounds like it might be a good index variable; check if it's unique\n",
      "  - one **`route`** has many stops (sounds obvious, but worth noting)\n",
      "  - also - one **`stop_id`** can have multiple **`routes`**. This is less obvious, since the data could have been collected on a per-route-stop basis (where the `on_street`, `cross_street`, and `location` are all the same, but the route is different).\n",
      "    - This **many-to-many** (`stop_id`-to-`route`) suggest that one SQL table may not be the best fit for analyzing this data. It also has subtler implications for how much we can reason about the busy-ness of any particular `route`, if many of its `stops` are shared with other `routes`. \n",
      "  - **`boardings`** and **`alightings`** are floats, so they are likely the averages\n",
      "  - **`month_beginning`** and **`daytype`** suggest we might have **`TimeSeries`** data\n",
      "  - **`location`** looks like lat-long pairing. Looking at the original data at [chicago data](), it doesn't *say* they're lat-long, but it has degree-symbol, which got dropped when exported into a CSV, and I've never heard the phrase 'long-lat', so it feels like a safe assumption, but an assumption nonetheless.\n",
      "\n",
      "## Basic stats\n",
      "Based on that, our only truly numerical columns (ignoring `location` for now) are `boardings` and `alightings`, so let's **`describe()`** those."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>stop_id</th>\n",
        "      <th>boardings</th>\n",
        "      <th>alightings</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>count</th>\n",
        "      <td>11593.000000</td>\n",
        "      <td>11593.000000</td>\n",
        "      <td>11593.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>mean</th>\n",
        "      <td>8137.552747</td>\n",
        "      <td>90.958164</td>\n",
        "      <td>90.957785</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>std</th>\n",
        "      <td>4931.401599</td>\n",
        "      <td>181.161159</td>\n",
        "      <td>175.251922</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>min</th>\n",
        "      <td>1.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25%</th>\n",
        "      <td>3836.000000</td>\n",
        "      <td>10.500000</td>\n",
        "      <td>12.600000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>50%</th>\n",
        "      <td>8083.000000</td>\n",
        "      <td>33.600000</td>\n",
        "      <td>38.200000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>75%</th>\n",
        "      <td>11839.000000</td>\n",
        "      <td>92.000000</td>\n",
        "      <td>97.100000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>max</th>\n",
        "      <td>17710.000000</td>\n",
        "      <td>3366.300000</td>\n",
        "      <td>3418.300000</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "            stop_id     boardings    alightings\n",
        "count  11593.000000  11593.000000  11593.000000\n",
        "mean    8137.552747     90.958164     90.957785\n",
        "std     4931.401599    181.161159    175.251922\n",
        "min        1.000000      0.000000      0.000000\n",
        "25%     3836.000000     10.500000     12.600000\n",
        "50%     8083.000000     33.600000     38.200000\n",
        "75%    11839.000000     92.000000     97.100000\n",
        "max    17710.000000   3366.300000   3418.300000"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Immediately interesting facts\n",
      "\n",
      " - the number of **`stop_ids`** is the same as the number of rows, so they are **unique** (but they aren't a straight set as the `max` is higher than the number of rows). \n",
      " - the means for `boardings` and `alightings` are almost (but not quite) identical - this makes sense if this data comprise the **entirety** of Chicago bus routes, i.e. every stop is accounted for.\n",
      " - the **standard deviation** is substantially *larger* than the **mean** for both `boardings` and `alightings`. There is a hard-min at 0 (as having negative `boardings` makes no sense), so there's some amount of tail to the right (above the mean) or something\n",
      "    \n",
      "## Column Ranges\n",
      "Another interesting thing to check is the **number of unique values** in any given column"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for col in df.columns:\n",
      "    print(\"{: >15} has {: 6} unique values\".format(col, df[col].unique().size))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "        stop_id has  11593 unique values\n",
        "      on_street has    365 unique values\n",
        "   cross_street has   1886 unique values\n",
        "         routes has    593 unique values\n",
        "      boardings has   2855 unique values\n",
        "     alightings has   2844 unique values\n",
        "month_beginning has      1 unique values\n",
        "        daytype has      1 unique values\n",
        "       location has  11591 unique values\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Immediately interesting:\n",
      "\n",
      "  - so much for `TimeSeries` for **`month_beginning`** or **`daytype`** as they are **all the same**; if we know we are only looking at this data set, we don't really need those columns, they're just metadata. However, let's leave them in because we wouldn't want all the analysis to go awry if we simply added November, 2012, or October Weekend data to the mix.\n",
      "  - **`location` is almost-but-not-quite unique**, it'd be interesting to find those rows and see if they share the same `on_street` and `cross_street`\n",
      "    - maybe one `stop_id` is e.g. heading north-south, while the other `stop_id` with the same location is heading east-west, so their `on_street` and `cross_street` are swapped?\n",
      "\n",
      "## Sanity Checking\n",
      "\n",
      "  - Do we have any null or **`NaN`-type values** that we should consider?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df[df.isnull().any(axis=1)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>stop_id</th>\n",
        "      <th>on_street</th>\n",
        "      <th>cross_street</th>\n",
        "      <th>routes</th>\n",
        "      <th>boardings</th>\n",
        "      <th>alightings</th>\n",
        "      <th>month_beginning</th>\n",
        "      <th>daytype</th>\n",
        "      <th>location</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>6635</th>\n",
        "      <td>9267</td>\n",
        "      <td>BELMONT</td>\n",
        "      <td>KEELER</td>\n",
        "      <td>NaN</td>\n",
        "      <td>62.4</td>\n",
        "      <td>35.2</td>\n",
        "      <td>10/01/2012</td>\n",
        "      <td>Weekday</td>\n",
        "      <td>(41.93897000, -87.73212000)</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9206</th>\n",
        "      <td>12548</td>\n",
        "      <td>ADDISON</td>\n",
        "      <td>LAKE SHORE</td>\n",
        "      <td>NaN</td>\n",
        "      <td>2.1</td>\n",
        "      <td>185.5</td>\n",
        "      <td>10/01/2012</td>\n",
        "      <td>Weekday</td>\n",
        "      <td>(41.94853216, -87.64355208)</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "      stop_id on_street cross_street routes  boardings  alightings  \\\n",
        "6635     9267   BELMONT       KEELER    NaN       62.4        35.2   \n",
        "9206    12548   ADDISON   LAKE SHORE    NaN        2.1       185.5   \n",
        "\n",
        "     month_beginning  daytype                     location  \n",
        "6635      10/01/2012  Weekday  (41.93897000, -87.73212000)  \n",
        "9206      10/01/2012  Weekday  (41.94853216, -87.64355208)  "
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This seems interesting - it's not impossible for a bus stop to not have a route - one can imagine a bus stop that has just been built, but that has had no routes scheduled onto it yet. However, that doesn't explain how e.g. 185 people **on average, per weekday** got off a bus that doesn't have a route.\n",
      "\n",
      "  - Perhaps it's a non-route shuttle bus that is included but not explained?\n",
      "  - Potentially coincidentally, there are 2 non-unique\\* `location` data points, perhaps these are those?\n",
      "\n",
      "\\* By 2 non-unique I mean we are missing two values from having a fully unique set. We could either have the same location show up 3 times, or 2 locations showing up twice\n",
      "\n",
      "\n",
      "  - What about 'empty'? Some columns (`boardings`, `alightings`) can reasonably have `0.0`, but our text columns probably shouldn't"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df[(df.on_street == \"\") | (df.cross_street == \"\") | (df.routes == \"\")]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>stop_id</th>\n",
        "      <th>on_street</th>\n",
        "      <th>cross_street</th>\n",
        "      <th>routes</th>\n",
        "      <th>boardings</th>\n",
        "      <th>alightings</th>\n",
        "      <th>month_beginning</th>\n",
        "      <th>daytype</th>\n",
        "      <th>location</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "Empty DataFrame\n",
        "Columns: [stop_id, on_street, cross_street, routes, boardings, alightings, month_beginning, daytype, location]\n",
        "Index: []"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "No empty columns,to deal with. \n",
      "\n",
      "Well, instead of leaving `NaN` lying around, let's replace it. That column is already a `str`, so let's pick some reasonably safe, not-route-name `str` to denote these, such as `UNKNOWN`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.fillna({\"routes\":\"UNKNOWN\"}, inplace=True)\n",
      "df[df.isnull().any(axis=1)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>stop_id</th>\n",
        "      <th>on_street</th>\n",
        "      <th>cross_street</th>\n",
        "      <th>routes</th>\n",
        "      <th>boardings</th>\n",
        "      <th>alightings</th>\n",
        "      <th>month_beginning</th>\n",
        "      <th>daytype</th>\n",
        "      <th>location</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "Empty DataFrame\n",
        "Columns: [stop_id, on_street, cross_street, routes, boardings, alightings, month_beginning, daytype, location]\n",
        "Index: []"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's find our duplicate `location`s and see what they look like."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## keep argument is new in pandas 0.17.1.\n",
      "## I think they expect you to delete the duplicated rows, so keep=False returns all the dups\n",
      "df[df.duplicated(\"location\", keep=False) == True]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>stop_id</th>\n",
        "      <th>on_street</th>\n",
        "      <th>cross_street</th>\n",
        "      <th>routes</th>\n",
        "      <th>boardings</th>\n",
        "      <th>alightings</th>\n",
        "      <th>month_beginning</th>\n",
        "      <th>daytype</th>\n",
        "      <th>location</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>3613</th>\n",
        "      <td>4865</td>\n",
        "      <td>MARINE DRIVE</td>\n",
        "      <td>IRVING PARK</td>\n",
        "      <td>146</td>\n",
        "      <td>128.4</td>\n",
        "      <td>17.6</td>\n",
        "      <td>10/01/2012</td>\n",
        "      <td>Weekday</td>\n",
        "      <td>(41.95420437, -87.64526199)</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9664</th>\n",
        "      <td>14143</td>\n",
        "      <td>CUMBERLAND</td>\n",
        "      <td>BLUE LINE STATION</td>\n",
        "      <td>81W</td>\n",
        "      <td>214.5</td>\n",
        "      <td>0.1</td>\n",
        "      <td>10/01/2012</td>\n",
        "      <td>Weekday</td>\n",
        "      <td>(41.98367954, -87.83902780)</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10978</th>\n",
        "      <td>16054</td>\n",
        "      <td>MARINE DRIVE</td>\n",
        "      <td>IRVING PARK</td>\n",
        "      <td>145</td>\n",
        "      <td>22.1</td>\n",
        "      <td>0.1</td>\n",
        "      <td>10/01/2012</td>\n",
        "      <td>Weekday</td>\n",
        "      <td>(41.95420437, -87.64526199)</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11462</th>\n",
        "      <td>17541</td>\n",
        "      <td>CUMBERLAND</td>\n",
        "      <td>BLUE LINE STATION</td>\n",
        "      <td>81W</td>\n",
        "      <td>0.0</td>\n",
        "      <td>437.9</td>\n",
        "      <td>10/01/2012</td>\n",
        "      <td>Weekday</td>\n",
        "      <td>(41.98367954, -87.83902780)</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "       stop_id     on_street       cross_street routes  boardings  alightings  \\\n",
        "3613      4865  MARINE DRIVE        IRVING PARK    146      128.4        17.6   \n",
        "9664     14143    CUMBERLAND  BLUE LINE STATION    81W      214.5         0.1   \n",
        "10978    16054  MARINE DRIVE        IRVING PARK    145       22.1         0.1   \n",
        "11462    17541    CUMBERLAND  BLUE LINE STATION    81W        0.0       437.9   \n",
        "\n",
        "      month_beginning  daytype                     location  \n",
        "3613       10/01/2012  Weekday  (41.95420437, -87.64526199)  \n",
        "9664       10/01/2012  Weekday  (41.98367954, -87.83902780)  \n",
        "10978      10/01/2012  Weekday  (41.95420437, -87.64526199)  \n",
        "11462      10/01/2012  Weekday  (41.98367954, -87.83902780)  "
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "They appear to be the exact **same** `on_street` and `cross_street`, but with **wildly varying** `boardings` and `alightings`. Not too sure what to make of this data; let's keep them distinct for now; we can merge them (or discard one?) later, if we find out more."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Table Design\n",
      "---\n",
      "Finally, it seems we have enough info to create appropriate tables to represent our data set. It seems, at least to me, that there are **3 separate tables** here, because the conditions for some change should only affect one table at a time.\n",
      "\n",
      "### stops\n",
      "\n",
      "  - `stop_id` exists at a physical location\n",
      "  - relevant fields for this description are `on_street`, `cross_street`, `location`.\n",
      "  - stop location has no immediate bearing on its ridership, nor even the routes (which are many-to-many, and can even be null, apparently).\n",
      "  \n",
      "### ridership\n",
      "\n",
      "  - `stop_id` has some ridership data (`boardings` and `alightings`), that may vary over time (`month_beginning` and `daytype`)\n",
      "  \n",
      "### routes\n",
      "\n",
      "  - each row: a single `stop_id` and a single `route` - **splitting up the `routes` column** as it exists now to allow some more granularity\n",
      "  - should be unique on the `stop_id`-`route` combination (even our duplicate `location`s have different `stop_id`s)\n",
      "  "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Making tables\n",
      "---\n",
      "\n",
      "Let's first make our **stops** table - the physical location\n",
      "\n",
      "  - convert **`location`** `str` to **`lat, long`** `float`s - takes a bit of massaging"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stops = df[[\"stop_id\", \"on_street\", \"cross_street\"]]\n",
      "latlong = df[\"location\"]\n",
      "## get rid of \"(\" and \")\" so after we split, we get str of numbers only\n",
      "latlong = latlong.str.replace(\"[() ]\",\"\").str.split(\",\", expand=True)\n",
      "latlong.rename(columns={0:\"lat\", 1:\"long\"}, inplace=True)\n",
      "## convert strings into floats, overwriting original columns\n",
      "latlong[\"lat\"] = latlong[\"lat\"].astype(float)\n",
      "latlong[\"long\"] = latlong[\"long\"].astype(float)\n",
      "\n",
      "## merge back with original \"stops\" table\n",
      "stops = pd.concat([stops, latlong], axis=1)\n",
      "print(stops)\n",
      "stops.describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "       stop_id       on_street         cross_street        lat       long\n",
        "0            1         JACKSON               AUSTIN  41.876322 -87.774105\n",
        "1            2         JACKSON  MAYFIELD (EXTENDED)  41.877067 -87.771318\n",
        "2            3         JACKSON               MENARD  41.876957 -87.769750\n",
        "3            4         JACKSON            5700 WEST  41.877024 -87.767451\n",
        "4            6         JACKSON                LOTUS  41.876513 -87.761446\n",
        "5            7         JACKSON            5351 WEST  41.876552 -87.758925\n",
        "6            8         JACKSON             LOCKWOOD  41.876564 -87.757313\n",
        "...        ...             ...                  ...        ...        ...\n",
        "11586    17704       MARQUETTE              CORNELL  41.775146 -87.585153\n",
        "11587    17705    STONY ISLAND         MARQUETTE RD  41.775385 -87.586113\n",
        "11588    17706    100TH STREET               PAXTON  41.713395 -87.569633\n",
        "11589    17707     43RD STREET            OAKENWALD  41.816856 -87.597573\n",
        "11590    17708     43RD STREET            LAKE PARK  41.816973 -87.599108\n",
        "11591    17709     43RD STREET             BERKELEY  41.816958 -87.600499\n",
        "11592    17710  S. SHORE DRIVE          76TH STREET  41.758946 -87.555606\n",
        "\n",
        "[11593 rows x 5 columns]\n"
       ]
      },
      {
       "html": [
        "<div style=\"max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>stop_id</th>\n",
        "      <th>lat</th>\n",
        "      <th>long</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>count</th>\n",
        "      <td>11593.000000</td>\n",
        "      <td>11593.000000</td>\n",
        "      <td>11593.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>mean</th>\n",
        "      <td>8137.552747</td>\n",
        "      <td>41.859281</td>\n",
        "      <td>-87.684087</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>std</th>\n",
        "      <td>4931.401599</td>\n",
        "      <td>0.096307</td>\n",
        "      <td>0.063595</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>min</th>\n",
        "      <td>1.000000</td>\n",
        "      <td>41.644158</td>\n",
        "      <td>-87.884297</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25%</th>\n",
        "      <td>3836.000000</td>\n",
        "      <td>41.779219</td>\n",
        "      <td>-87.725575</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>50%</th>\n",
        "      <td>8083.000000</td>\n",
        "      <td>41.869851</td>\n",
        "      <td>-87.681095</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>75%</th>\n",
        "      <td>11839.000000</td>\n",
        "      <td>41.937966</td>\n",
        "      <td>-87.639501</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>max</th>\n",
        "      <td>17710.000000</td>\n",
        "      <td>42.064700</td>\n",
        "      <td>-87.525699</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 50,
       "text": [
        "            stop_id           lat          long\n",
        "count  11593.000000  11593.000000  11593.000000\n",
        "mean    8137.552747     41.859281    -87.684087\n",
        "std     4931.401599      0.096307      0.063595\n",
        "min        1.000000     41.644158    -87.884297\n",
        "25%     3836.000000     41.779219    -87.725575\n",
        "50%     8083.000000     41.869851    -87.681095\n",
        "75%    11839.000000     41.937966    -87.639501\n",
        "max    17710.000000     42.064700    -87.525699"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now the **ridership** table. Note that we could do a couple things here if we were concerned about space\n",
      "\n",
      "  - could **delete `month_beginning, daytype`**\n",
      "  - OR canonical **month 0**, just store int\n",
      "  - **`daytype`** as **bool** (weekend, weekday), or at least **categorical** (holiday?)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ridership = df[[\"stop_id\", \"boardings\", \"alightings\", \"month_beginning\", \"daytype\"]]\n",
      "ridership"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>stop_id</th>\n",
        "      <th>boardings</th>\n",
        "      <th>alightings</th>\n",
        "      <th>month_beginning</th>\n",
        "      <th>daytype</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>1</td>\n",
        "      <td>183.4</td>\n",
        "      <td>150.0</td>\n",
        "      <td>10/01/2012</td>\n",
        "      <td>Weekday</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>2</td>\n",
        "      <td>5.3</td>\n",
        "      <td>0.2</td>\n",
        "      <td>10/01/2012</td>\n",
        "      <td>Weekday</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>3</td>\n",
        "      <td>8.3</td>\n",
        "      <td>0.7</td>\n",
        "      <td>10/01/2012</td>\n",
        "      <td>Weekday</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>4</td>\n",
        "      <td>17.9</td>\n",
        "      <td>3.0</td>\n",
        "      <td>10/01/2012</td>\n",
        "      <td>Weekday</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>6</td>\n",
        "      <td>74.0</td>\n",
        "      <td>11.2</td>\n",
        "      <td>10/01/2012</td>\n",
        "      <td>Weekday</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5</th>\n",
        "      <td>7</td>\n",
        "      <td>14.3</td>\n",
        "      <td>2.5</td>\n",
        "      <td>10/01/2012</td>\n",
        "      <td>Weekday</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6</th>\n",
        "      <td>8</td>\n",
        "      <td>62.4</td>\n",
        "      <td>14.1</td>\n",
        "      <td>10/01/2012</td>\n",
        "      <td>Weekday</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>...</th>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11586</th>\n",
        "      <td>17704</td>\n",
        "      <td>69.3</td>\n",
        "      <td>321.3</td>\n",
        "      <td>10/01/2012</td>\n",
        "      <td>Weekday</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11587</th>\n",
        "      <td>17705</td>\n",
        "      <td>81.2</td>\n",
        "      <td>62.7</td>\n",
        "      <td>10/01/2012</td>\n",
        "      <td>Weekday</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11588</th>\n",
        "      <td>17706</td>\n",
        "      <td>3.6</td>\n",
        "      <td>49.5</td>\n",
        "      <td>10/01/2012</td>\n",
        "      <td>Weekday</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11589</th>\n",
        "      <td>17707</td>\n",
        "      <td>21.0</td>\n",
        "      <td>69.1</td>\n",
        "      <td>10/01/2012</td>\n",
        "      <td>Weekday</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11590</th>\n",
        "      <td>17708</td>\n",
        "      <td>24.8</td>\n",
        "      <td>0.9</td>\n",
        "      <td>10/01/2012</td>\n",
        "      <td>Weekday</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11591</th>\n",
        "      <td>17709</td>\n",
        "      <td>14.7</td>\n",
        "      <td>0.9</td>\n",
        "      <td>10/01/2012</td>\n",
        "      <td>Weekday</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11592</th>\n",
        "      <td>17710</td>\n",
        "      <td>44.6</td>\n",
        "      <td>250.1</td>\n",
        "      <td>10/01/2012</td>\n",
        "      <td>Weekday</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>11593 rows \u00d7 5 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "       stop_id  boardings  alightings month_beginning  daytype\n",
        "0            1      183.4       150.0      10/01/2012  Weekday\n",
        "1            2        5.3         0.2      10/01/2012  Weekday\n",
        "2            3        8.3         0.7      10/01/2012  Weekday\n",
        "3            4       17.9         3.0      10/01/2012  Weekday\n",
        "4            6       74.0        11.2      10/01/2012  Weekday\n",
        "5            7       14.3         2.5      10/01/2012  Weekday\n",
        "6            8       62.4        14.1      10/01/2012  Weekday\n",
        "...        ...        ...         ...             ...      ...\n",
        "11586    17704       69.3       321.3      10/01/2012  Weekday\n",
        "11587    17705       81.2        62.7      10/01/2012  Weekday\n",
        "11588    17706        3.6        49.5      10/01/2012  Weekday\n",
        "11589    17707       21.0        69.1      10/01/2012  Weekday\n",
        "11590    17708       24.8         0.9      10/01/2012  Weekday\n",
        "11591    17709       14.7         0.9      10/01/2012  Weekday\n",
        "11592    17710       44.6       250.1      10/01/2012  Weekday\n",
        "\n",
        "[11593 rows x 5 columns]"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Routes\n",
      "---\n",
      "\n",
      "We can't take the `DataFrame` slice as-is, because we want to split out the `route` field form the list of `routes`.\n",
      "Borrowing heavily from [this SO answer](http://stackoverflow.com/a/21032532/2272638)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "routes = df.routes.str.split(\",\", expand=True).stack()\n",
      "routes.index = routes.index.droplevel(-1)\n",
      "routes.name = \"route\"\n",
      "subdf = df.join(routes)\n",
      "routes = subdf[[\"stop_id\", \"route\"]]\n",
      "routes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>stop_id</th>\n",
        "      <th>route</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>1</td>\n",
        "      <td>126</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>2</td>\n",
        "      <td>126</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>3</td>\n",
        "      <td>126</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>4</td>\n",
        "      <td>126</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>6</td>\n",
        "      <td>126</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5</th>\n",
        "      <td>7</td>\n",
        "      <td>126</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6</th>\n",
        "      <td>8</td>\n",
        "      <td>126</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>...</th>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11589</th>\n",
        "      <td>17707</td>\n",
        "      <td>43</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11590</th>\n",
        "      <td>17708</td>\n",
        "      <td>43</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11591</th>\n",
        "      <td>17709</td>\n",
        "      <td>43</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11592</th>\n",
        "      <td>17710</td>\n",
        "      <td>N5</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11592</th>\n",
        "      <td>17710</td>\n",
        "      <td>6</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11592</th>\n",
        "      <td>17710</td>\n",
        "      <td>26</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11592</th>\n",
        "      <td>17710</td>\n",
        "      <td>71</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>15273 rows \u00d7 2 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 64,
       "text": [
        "       stop_id route\n",
        "0            1   126\n",
        "1            2   126\n",
        "2            3   126\n",
        "3            4   126\n",
        "4            6   126\n",
        "5            7   126\n",
        "6            8   126\n",
        "...        ...   ...\n",
        "11589    17707    43\n",
        "11590    17708    43\n",
        "11591    17709    43\n",
        "11592    17710    N5\n",
        "11592    17710     6\n",
        "11592    17710    26\n",
        "11592    17710    71\n",
        "\n",
        "[15273 rows x 2 columns]"
       ]
      }
     ],
     "prompt_number": 64
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, let's create our tables in MySQL"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "certfile = os.path.join(os.environ[\"HOME\"], \".mysql.cert\")\n",
      "from sqlalchemy import create_engine\n",
      "with open(certfile) as fh:\n",
      "    engine = create_engine(fh.read().strip(), echo=False)\n",
      "engine"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 65,
       "text": [
        "Engine(mysql://root:***@127.0.0.1/chicagoBus)"
       ]
      }
     ],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stops.to_sql(name=\"stops\", con=engine, if_exists=\"fail\")\n",
      "ridership.to_sql(name=\"ridership\", con=engine, if_exists=\"fail\")\n",
      "routes.to_sql(name=\"routes\", con=engine, if_exists=\"fail\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 67
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## What about more data?\n",
      "---\n",
      "\n",
      "Pretty much just re-do everything, and then **`append`** rather than **`fail`** if table exists (since they do).\n",
      "\n",
      "This would miss any issues we didn't see during this analysis, e.g. `NaN` for `lat-long`, but if the data is well-formed, should work smoothly."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def makeStops(df, engine):\n",
      "    stops = df[[\"stop_id\", \"on_street\", \"cross_street\"]]\n",
      "    latlong = df[\"location\"]\n",
      "    ## get rid of \"(\" and \")\" so after we split, we get str of numbers only\n",
      "    latlong = latlong.str.replace(\"[() ]\",\"\").str.split(\",\", expand=True)\n",
      "    latlong.rename(columns={0:\"lat\", 1:\"long\"}, inplace=True)\n",
      "    ## convert strings into floats, overwriting original columns\n",
      "    latlong[\"lat\"] = latlong[\"lat\"].astype(float)\n",
      "    latlong[\"long\"] = latlong[\"long\"].astype(float)\n",
      "    \n",
      "    ## merge back with original \"stops\" table\n",
      "    stops = pd.concat([stops, latlong], axis=1)\n",
      "    stops.to_sql(name=\"stops\", con=engine, if_exists=\"append\")\n",
      "\n",
      "def makeRidership(df, engine):\n",
      "    ridership = df[[\"stop_id\", \"boardings\", \"alightings\", \"month_beginning\", \"daytype\"]]\n",
      "    ridership.to_sql(name=\"ridership\", con=engine, if_exists=\"append\")\n",
      "\n",
      "def makeRoutes(df, engine):\n",
      "    ## get rid of NaNs\n",
      "    df.fillna({\"routes\":\"UNKNOWN\"}, inplace=True)\n",
      "    ## split routes from csv to multiple rows\n",
      "    routes = df.routes.str.split(\",\", expand=True).stack()\n",
      "    routes.index = routes.index.droplevel(-1)\n",
      "    routes.name = \"route\"\n",
      "    ## join it such that we don't lose the original indices\n",
      "    subdf = df.join(routes)\n",
      "    routes = subdf[[\"stop_id\", \"route\"]]\n",
      "    routes.to_sql(name=\"routes\", con=engine, if_exists=\"append\")\n",
      "\n",
      "def appendNewCsv(csvfile):\n",
      "    df = pd.read_csv(csvfile)\n",
      "    certfile = os.path.join(os.environ[\"HOME\"], \".mysql.cert\")\n",
      "    with open(certfile) as fh:\n",
      "        engine = create_engine(fh.read().strip(), echo=False)\n",
      "    stops = makeStops(df, engine)\n",
      "    ridership = makeRidership(df, engine)\n",
      "    routes = makeRoutes(df, engine)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}